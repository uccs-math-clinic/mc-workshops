{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent and its Ubiquity in Machine Learning\n",
    "\n",
    "In this notebook, we introduce the gradient descent algorithm which is far and away the most popular optimization algorithm in machine learning. Before we can talk about things like \"optimization\" or \"machine learning\" however, we need to define what exactly we mean by these terms and in particular how they are used in this notebook. We formulate these ideas from the ground up, and assume only a working knowledge of the material covered in an introductory Calculus course. Our primary motivation for this is provide clarity in technical machine learning contexts and to disambiguate the wide variety of popular buzzwords which pervade the field in a context which is as accessible as possible to those who wish to learn.\n",
    "\n",
    "### Software Prerequisites\n",
    "\n",
    "The following Python libraries are prerequisites to run this notebook; simply run the following code block to install them. They are also listed in the `requirements.txt` file in the root of this notebook's [GitHub repository](https://github.com/uccs-math-clinic/mc-workshops)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%pip install matplotlib==3.5.1 \\\n",
    "             numpy==1.21.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python kernel must be restarted after running the above code block for the first time within a particular virtual environment. This may be accomplished by navigating to `Kernel -> Restart` in the menu bar.\n",
    "\n",
    "With our package dependencies installed, we can run the following cell in order to import the packages needed for this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import a few different libraries that make our work a bit easier.\n",
    "# We also give them each aliases (the part after \"as\") which make them\n",
    "# a little easier to remember; the ones shown below are those used \n",
    "# most commonly, but you can call these whatever you want! This practice\n",
    "# is quite prevalent in Python as a whole, and doubly so in data science.\n",
    "#\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# This allows us to run animations in this notebook; this isn't necessary\n",
    "# for the vast majority of notebooks, but it does serve as a useful teaching\n",
    "# tool.\n",
    "#\n",
    "%matplotlib notebook\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that are prerequisites are out of the way, we begin by asking a very basic question and immediately providing a very basic answer:\n",
    "\n",
    "#### What is machine learning?\n",
    "\n",
    "One answer to this question - and the one which we will use as our working definition to guide our intuition - is that machine learning is nothing more than a particular mathematical and/or computational model which makes predictions about new data based on optimizations \"learned\" from previous data sets. As many useful answers do, this characterization immediately provides motivation for our next question: \n",
    "\n",
    "#### What does it mean for a model or a machine to \"learn\"?\n",
    "\n",
    "It is at this point that we narrow our focus by providing some measure of technical precision; while the idea of generalized learning machines has inspired decades of fantastic science fiction and stimulates rich discussion in philosophy and ethics to this day, it is somewhat far afield of what we will accomplish in this notebook. Instead, we provide a more constrained yet still intuitive proposition: a machine \"learns\" by way of an iterative learning process which by some algorithm or another (spoiler: that algorithm will predominantly be gradient descent) changes parameters in a model in response to data in order to make increasingly accurate predictions about some aspect of that data. In short, we wish to optimize - and in particular maximize - the accuracy with which our model can make predictions.\n",
    "\n",
    "This definition provides some immediate direction regarding some things we might need in order to create a learning machine. The following items turn out to form a fairly complete list of the pieces we need in order to create our iterative learning process:\n",
    "\n",
    "- A predictive model with parameters which we can tune.\n",
    "- Some sort of measure of the accuracy of the predictions that our model makes.\n",
    "- An iterative algorithm which adjusts model parameters in order to move our model closer to its maximum accuracy.\n",
    "\n",
    "In general, the exact nature of these three components will greatly depend both on the problem we're looking to solve as well as the data set with which we are working. We can, however, formulate some helpful restrictions about the behavior of these components.\n",
    "\n",
    "We encounter the first of these by examining just a bit more closely what exactly we mean by our measure of accuracy. Because the space of possible predictions in a model is often near endless, one finds that any attempt to directly compare one prediction against all other possible predictions is at best computationally expensive and at worst completely futile (imagine trying to measure how good you are at darts by comparing against all the places that you _didn't_ hit). We can further convince ourselves that trying somehow to optimize that accuracy be for all practical purposes an impossible endeavour except perhaps under very exceptional circumstances.\n",
    "\n",
    "For this reason, we instead take a rather simpler approach - we simply measure how different the data is from our model's prediction. We call this error our **loss function** (also often referred to as an **objective function**; these two terms are commonly interchanged, so it is good to become comfortable with using them interchangeably) and a moment's consideration should convince the reader that our model's _maximum accuracy_ is attained when our error is as small as possible - i.e., when the loss function attains its _minimum value_. This insight is critical, as it provides the foundation for our learning machines and captures in a general sense what a learning model is.\n",
    "\n",
    "We have now established in a broad sense the requirements for candidates for our loss function. We wish for this function to compare model predictions to actual data, and to output some non-negative value which serves as a measure of the error (or the loss) of the model's prediction. One simple loss function we could use would be to simply take the absolute value of the difference between the values predicted by our model and the values in the data set:\n",
    "\n",
    "$$ L = | \\textbf{x}_{predicted} - \\textbf{x}_{data} | $$ \n",
    "\n",
    "However, because we wish to minimize that error, we further want our loss function to be differentiable in such a way that we can find the extrema of the loss function. We also want as few extrema as possible (ideally only ever one) in the loss function so that we have some guarantee that our model isn't only accurate in some local area of the data set. A common way to achieve both of these desired behaviors while retaining an intuitive sense of accuracy in the loss function is to divide the square of the difference between each predicted value $\\bar{x}_i$ and its corresponding actual value $x_i$ in the data set by the number of elements $n$ in the set. In doing so, our loss function becomes the mean squared error (MSE) function:\n",
    "\n",
    "$$ L = \\frac{1}{n}\\sum\\limits_{i=0}^{n}{\\left( \\bar{x}_i - x_i \\right)^2} $$\n",
    "\n",
    "This function quite pleasantly only has a single extreme point, which is a minimum; one consequence of this fact is that we can _always_ find a minimum for this particular loss function - in other words, given a particular model paired with this loss function, optimizing this loss function will _always yield an optimal prediction within some neighborhood of our predictive model_. It is extremely important to keep in mind, however, that this optimal prediction is not necessarily a _global_ minimum and that optimizing this loss function does not guarantee that we achieve the best possible accuracy; finding global extrema is in fact a quite non-trivial field of study within machine learning. The data generated in this notebook is not prone to this problem of local optimization, and so we defer the study of this problem to a later workshop.\n",
    "\n",
    "Now that we have a loss function with all sorts of desirable behaviors, we can talk about how to minimize this function via gradient descent.\n",
    "\n",
    "#### The Gradient Descent Algorithm\n",
    "\n",
    "Our goal in general is to minimize a loss function for a particular model. Because we chose a well-behaved (i.e., differentiable) loss function to work with, we can go about this without a great deal of theoretical development. Recall that the gradient in general represents a direction of greatest change of a function (in one dimension - which is where we will work initially - the gradient simply reduces to taking the derivative of a function). The point in which we are interested is precisely the opposite; that is, we are looking for a neighborhood in which there is as _little_ change as possible. The approach we take to minimizing the loss function then is to calculate the gradient of the loss function with respect to whatever parameters our particular model contains and then to proceed in _exactly the opposite direction_ which the gradient indicates is the direction of maximum change. The following example shows this process for the function $y = x^2$, whose gradient is $\\nabla y = 2x$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(initial_guess=-3, train_iterations=50):\n",
    "    \"\"\"\n",
    "    We implement gradient descent as its own function here so that none of\n",
    "    the variables declared here overwrite variables from any other code cells\n",
    "    in the notebook.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a new figure to add plots to.\n",
    "    #\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Plot y=x^2 for reference.\n",
    "    #\n",
    "    x = np.linspace(-5, 5, 100)\n",
    "    y = x ** 2\n",
    "    ax.plot(x, y)\n",
    "\n",
    "\n",
    "    # We make our first (bad) guess at x = -3 for our minimum.\n",
    "    #\n",
    "    min_x_guess = initial_guess\n",
    "\n",
    "    # Calculate our initial gradient; remember that we're trying\n",
    "    # to make this number as close to 0 as possible, which indicates\n",
    "    # that we've found a minimum.\n",
    "    #\n",
    "    gradient = 2 * min_x_guess\n",
    "\n",
    "    # We're going to say that we've found our minimum once our\n",
    "    # gradient is less than this value. This should always be\n",
    "    # some amount greater than zero, since we'll never achieve\n",
    "    # perfect accuracy unless we're utilizing an analytic solution.\n",
    "    #\n",
    "    acceptable_min_gradient = 0.01\n",
    "\n",
    "    # This value indicates how much we should change our current\n",
    "    # best guess in response to the gradient. Try changing this\n",
    "    # value to observe the effect of this value on the model's\n",
    "    # learning. A word of warning - if you set it to one or more,\n",
    "    # your predictions will actually diverge (and you'll need to\n",
    "    # restart this notebook :).\n",
    "    #\n",
    "    learning_rate = 0.01\n",
    "\n",
    "    # We'll be plotting our gradient function as dx vs. dy\n",
    "    #\n",
    "    dx = np.linspace(-5, 5)\n",
    "    dy = gradient * dx - (min_x_guess ** 2)\n",
    "    z, = ax.plot(dx, dy)\n",
    "\n",
    "    ax.set_ylim(bottom=-5)\n",
    "\n",
    "    # Run until the absolute value of the gradient is close to zero\n",
    "    # or we hit 1000 iterations.\n",
    "    #\n",
    "    for i in range(train_iterations):        \n",
    "        # Set new guess for minimum x - this is the learning step!\n",
    "        #\n",
    "        min_x_guess = min_x_guess - (learning_rate * gradient)\n",
    "\n",
    "        # Calculate the new gradient and corresponding line\n",
    "        #\n",
    "        gradient = 2 * min_x_guess\n",
    "        dy = gradient * dx - (min_x_guess ** 2)\n",
    "\n",
    "        # Plot new line values - don't worry too much about this part;\n",
    "        # this is just to run the animation.\n",
    "        #\n",
    "        z.set_ydata(dy)\n",
    "\n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "\n",
    "        # Comment out this line if you want to see how fast this can converge!\n",
    "        time.sleep(0.05)\n",
    "\n",
    "    print('Minimum gradient after {} iterations occurs at x={}; minimized gradient value is {}.'.format(\n",
    "        train_iterations,\n",
    "        min_x_guess,\n",
    "        gradient,\n",
    "    ))\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "# Run the gradient_descent function defined above.\n",
    "#\n",
    "gd_fig, gd_ax = gradient_descent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning a Model - Combining Gradient Descent with a Loss Function\n",
    "\n",
    "Now that we have two big tools in our toolbox, we're finally ready to train our very own model! We're going to start simple by randomly generating some data that's pretty close to linear. This will serve as our practice data set.\n",
    "\n",
    "Recall that the last item on our learning machine list is the model itself. In general, this choice should be driven by the nature of the data set; some data sets lend themselves more naturally to models which are designed to detect anomalous data, others toward neural network models, and yet others to data clustering models. Since we're working with data which is linear, we're going create a learning machine which models the generated data set by a linear function. Our model is then simply the equation for a line (we replace the standard $m$ and $b$ notation with $\\theta_1$ and $\\theta_2$ respectively in order to emphasize the fact that these are the values which we can learn in response to our calculated gradient):\n",
    "\n",
    "$$ y_{predicted} = \\theta_1 x + \\theta_2 $$\n",
    "\n",
    "\n",
    "From this, we can formulate our mean squared error function from above as the function upon which we perform gradient descent in order to optimize; recall that $(x_i, y_i)$ represents each point from our data set and that $\\bar{y}_i$ represents the _predicted_ value corresponding to $x_i$:\n",
    "\n",
    "$$ \n",
    "\\begin{aligned}\n",
    "L &= \\frac{1}{n}\\sum\\limits_{i=0}^{n}{\\left( \\bar{y}_i - y_i \\right)^2} \\\\\n",
    "  &= \\frac{1}{n}\\sum\\limits_{i=0}^{n}{\\left[(\\theta_1 x_i + \\theta_2) - y_i \\right]^2}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "Since we want to adjust both the slope and y-intercept, our gradient must differentiate with respect to the parameters we wish to learn, i.e., our model's learned slope $\\theta_1$ and y-intercept $\\theta_2$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\nabla y_{predicted} = \\begin{pmatrix}\n",
    "        \\frac{\\partial L}{\\partial \\theta_1} \\\\ \\frac{\\partial L}{\\partial \\theta_2}\n",
    "    \\end{pmatrix} = \\begin{pmatrix}\n",
    "        \\frac{1}{n}\\sum\\limits_{i=0}^{n}{2 \\left[ (\\theta_1 x_i + \\theta_2) - y_i \\right] x_i} \\\\\n",
    "        \\frac{1}{n}\\sum\\limits_{i=0}^{n}{2 \\left[ (\\theta_1 x_i + \\theta_2) - y_i \\right]}\n",
    "    \\end{pmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "To recapitulate our progress thus far, we have at this point created a model (a line) which we think stands a good chance of fitting our data set (which we know will, of course - we generated the data set from a line, after all!), and we then derived an objective (loss) function by plugging our model into the mean squared error function. We then calculated the gradient of that loss function with respect to the parameters we wish to change in order to minimize the loss function. We are therefore now ready to apply the gradient descent algorithm to our model and see how it performs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Since our gradient calculation is a bit non-trivial, we're\n",
    "# going to put that calculation into its own function. This\n",
    "# code is nothing more than the gradient function defined\n",
    "# above.\n",
    "#\n",
    "def calculate_mse_gradient(slope, intercept, x_vals, y_vals):\n",
    "    # Calculate mean standard error gradient\n",
    "    #\n",
    "    abs_error = (slope * x_vals + intercept) - y_vals\n",
    "\n",
    "    d_slope = np.sum(2 * abs_error * x_vals) / len(x_vals)\n",
    "    d_intercept = np.sum(2 * (abs_error)) / len(x_vals)\n",
    "\n",
    "    # Calculate mean standard error value\n",
    "    #\n",
    "    mse = np.sum(np.power(abs_error, 2)) / len(x_vals)\n",
    "\n",
    "    return (d_slope, d_intercept, mse)\n",
    "\n",
    "\n",
    "def linear_regression_mse(m, b, left_xlim=0, right_xlim=5, train_iterations=50):\n",
    "    # Create a new figure to add plots to.\n",
    "    #\n",
    "    fig, [ax, err_ax] = plt.subplots(2, 1)\n",
    "    ax.set_title('Predicted Line')\n",
    "    err_ax.set_title('Error (MSE)')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "\n",
    "    # We'll make our first (terrible) guess to be the line y = 0.\n",
    "    #\n",
    "    theta1 = 0\n",
    "    theta2 = 0\n",
    "\n",
    "    # This value indicates how much we should change our current\n",
    "    # best guess in response to the gradient. Try changing this\n",
    "    # value to observe the effect of this value on the model's\n",
    "    # learning. A word of warning - if you set it to one or more,\n",
    "    # your predictions will actually diverge (and you'll need to\n",
    "    # restart this notebook :).\n",
    "    #\n",
    "    learning_rate = 0.01\n",
    "\n",
    "    # We'll use some random integers to create a line from which we\n",
    "    # generate test data.\n",
    "    # This code generates the scatter plot from which we'll learn\n",
    "    # parameters (slope and y-intercept, in our case) for our model.\n",
    "    #\n",
    "    x = np.linspace(left_xlim, right_xlim, 100)[:, np.newaxis]\n",
    "    y = m * x + b + (2 * np.random.randn(100, 1))\n",
    "    ax.scatter(x, y, color='black')\n",
    "\n",
    "    # Calculate initial gradient and error values.\n",
    "    #\n",
    "    dtheta1, dtheta2, err = calculate_mse_gradient(theta1, theta2, x, y)\n",
    "\n",
    "    err_vals = [err]\n",
    "\n",
    "    # Plot our model function - it'll initially just be a horizontal line\n",
    "    # Since we initialized the theta_1 and theta_2 variables to 0. Try\n",
    "    # changing those values to see how different initial guesses affect\n",
    "    # training!\n",
    "    #\n",
    "    y_predicted = theta1 * x + theta2\n",
    "    z, = ax.plot(x, y_predicted, color='orange')\n",
    "    e, = err_ax.plot(np.arange(0, len(err_vals)), err_vals)\n",
    "    \n",
    "    err_ax.set_ylim(bottom=0)\n",
    "    err_ax.set_xlim(left=0, right=train_iterations)\n",
    "\n",
    "    # Iterate the number of times specified in train_iterations.\n",
    "    #\n",
    "    for i in range(train_iterations):\n",
    "\n",
    "        # Change theta_1 and theta_2 in response to the gradient - this is \n",
    "        # the learning step.\n",
    "        #\n",
    "        theta1 = theta1 - (learning_rate * dtheta1)\n",
    "        theta2 = theta2 - (learning_rate * dtheta2)\n",
    "\n",
    "        # Calculate the new gradient and corresponding line\n",
    "        #\n",
    "        dtheta1, dtheta2, err = calculate_mse_gradient(theta1, theta2, x, y)\n",
    "        y_predicted = theta1 * x + theta2\n",
    "        err_vals.append(err)\n",
    "\n",
    "        # Plot new line values - as before, this code is just for\n",
    "        # animation purposes.\n",
    "        #\n",
    "        z.set_ydata(y_predicted)\n",
    "        e.set_xdata(np.arange(0, len(err_vals)))\n",
    "        e.set_ydata(err_vals)\n",
    "        \n",
    "\n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "\n",
    "        # Comment out this line if you want to see how fast this can converge!\n",
    "        time.sleep(0.05)\n",
    "\n",
    "    print('Learned slope after {} iterations is {}; control value was {}.'.format(\n",
    "        train_iterations,\n",
    "        theta1,\n",
    "        m,\n",
    "    ))\n",
    "\n",
    "    print('Learned y-intercept after {} iterations is {}; control value was {}.'.format(\n",
    "        train_iterations,\n",
    "        theta2,\n",
    "        b,\n",
    "    ))\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "mse_fig, mse_ax = linear_regression_mse(10, 5, train_iterations=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative Loss Functions\n",
    "\n",
    "In this final section of the notebook, we turn things over to the reader to derive and code up a gradient function for the mean squared logarithmic error (MSLE) function, which is very similar to the mean squared error function we've already worked with. While the MSE function heavily penalizes significant data outliers (since that loss function increases as the square of the difference between data points), the MSLE function relaxes that penalty quite a bit by taking the square of the difference of the _logarithm_ of the data points:\n",
    "\n",
    "$$ \n",
    "\\begin{aligned}\n",
    "L_{MSLE} &= \\frac{1}{n}\\sum\\limits_{i=0}^{n}{\\left[ \\ln{(\\bar{y}_i + 1)} - \\ln{(y_i + 1)} \\right]^2} \\\\\n",
    "  &= \\frac{1}{n}\\sum\\limits_{i=0}^{n}{\\left[\\ln{(\\theta_1 x_i + \\theta_2 + 1)} - \\ln{(y_i + 1)} \\right]^2}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Due to the logarithm terms in the loss function, the domain of this function requires non-negative values both for predicted and measured values; in practice, this restriction is a very minor hindrance as input data and predicted data can easily be normalized to the unit interval $[0, 1]$. In the code cell below, we simply shift our domain to be $[0, 10]$ for the sake of simplicity.\n",
    "\n",
    "We've outlined the code below and denoted the section into which the reader can encode the derived gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where you should encode the new gradient value for the MSLE function\n",
    "# defined above.\n",
    "#\n",
    "def calculate_msle_gradient(slope, intercept, x_vals, y_vals):\n",
    "    # Calculate mean standard error gradient\n",
    "    #\n",
    "    predicted_vals = slope * x_vals + intercept\n",
    "    abs_error = np.log(predicted_vals + 1) - np.log(y_vals + 1)\n",
    "\n",
    "    # These are the partial derivatives you need to encode.\n",
    "    #\n",
    "    d_slope = np.sum(abs_error / (predicted_vals + 1) * x_vals) / len(x_vals)\n",
    "    d_intercept = np.sum(abs_error / (predicted_vals + 1)) / len(x_vals)\n",
    "\n",
    "    # Calculate mean standard logarithmic error value\n",
    "    #\n",
    "    msle = np.sum(abs_error ** 2) / len(x_vals)\n",
    "\n",
    "    return (d_slope, d_intercept, msle)\n",
    "\n",
    "\n",
    "# Everything below here is automatically done - no need to change\n",
    "# anything below this line, though you're encouraged to read through\n",
    "# it to better understand how to implement this algorithm!\n",
    "#\n",
    "def linear_regression_msle(m, b, left_xlim=0, right_xlim=5, train_iterations=50):\n",
    "    assert(right_xlim > left_xlim)\n",
    "    assert(left_xlim >= 0)\n",
    "    \n",
    "    # Create a new figure to add plots to.\n",
    "    #\n",
    "    fig, [ax, err_ax] = plt.subplots(2, 1)\n",
    "    ax.set_title('Predicted Line')\n",
    "    err_ax.set_title('Error (MSLE)')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Initialize guesses\n",
    "    #\n",
    "    theta1 = 0\n",
    "    theta2 = 0\n",
    "\n",
    "    # Note how much higher this is than for the Mean Squared Error (MSE)!\n",
    "    #\n",
    "    learning_rate = 1.0\n",
    "\n",
    "    # Generate test data\n",
    "    #\n",
    "    x = np.linspace(left_xlim, right_xlim, 100)[:, np.newaxis]\n",
    "    y = m * x + b + (2 * np.random.randn(100, 1))\n",
    "    ax.scatter(x, y, color='black')\n",
    "\n",
    "    # Calculate initial gradient and error values.\n",
    "    #\n",
    "    dtheta1, dtheta2, err = calculate_msle_gradient(theta1, theta2, x, y)\n",
    "\n",
    "    err_vals = [err]\n",
    "\n",
    "    # Plot our initial model function.\n",
    "    #\n",
    "    y_predicted = theta1 * x + theta2\n",
    "    z, = ax.plot(x, y_predicted, color='orange')\n",
    "    e, = err_ax.plot(np.arange(0, len(err_vals)), err_vals)\n",
    "    \n",
    "    err_ax.set_ylim(bottom=0)\n",
    "    err_ax.set_xlim(left=0, right=train_iterations)\n",
    "\n",
    "\n",
    "    # Iterate the number of times specified in train_iterations.\n",
    "    #\n",
    "    for i in range(train_iterations):\n",
    "\n",
    "        # Change theta_1 and theta_2 in response to the gradient - this is \n",
    "        # the learning step.\n",
    "        #\n",
    "        theta1 = theta1 - (learning_rate * dtheta1)\n",
    "        theta2 = theta2 - (learning_rate * dtheta2)\n",
    "\n",
    "        # Calculate the new gradient and corresponding line\n",
    "        #\n",
    "        dtheta1, dtheta2, err = calculate_msle_gradient(theta1, theta2, x, y)\n",
    "        y_predicted = theta1 * x + theta2\n",
    "        err_vals.append(err)\n",
    "\n",
    "        # Plot new line values - as before, this code is just for\n",
    "        # animation purposes.\n",
    "        #\n",
    "        z.set_ydata(y_predicted)\n",
    "        e.set_xdata(np.arange(0, len(err_vals)))\n",
    "        e.set_ydata(err_vals)\n",
    "        \n",
    "\n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "\n",
    "\n",
    "    print('Learned slope after {} iterations is {}; control value was {}.'.format(\n",
    "        train_iterations,\n",
    "        theta1,\n",
    "        m,\n",
    "    ))\n",
    "\n",
    "    print('Learned y-intercept after {} iterations is {}; control value was {}.'.format(\n",
    "        train_iterations,\n",
    "        theta2,\n",
    "        b,\n",
    "    ))\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "msle_fig, msle_ax = linear_regression_msle(m=10, b=3, train_iterations=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
